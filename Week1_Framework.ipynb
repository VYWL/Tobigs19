{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사한 기능 및 모듈을 모아둔 도구인 라이브러리는 사용자가 호출을 하며 제어하는 방식인데에 반해, \n",
    "라이브러리 및 정의들을 포함하는 구조체인 프레임워크는 틀 안에 제어를 하는 흐름이 이미 존재한다는 점에서 차이가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝은 머신러닝 알고리즘 중 인공신경망을 기반으로 한 방법들 모두를 의미합니다!\n",
    "따라서, 딥러닝은 머신러닝의 범주 안에 포함되는 관계입니다.\n",
    "\n",
    "머신러닝은 사용자가 규칙을 일일이 정의하지 않아도, 자동적으로 데이터에서 규칙을 학습히는 알고리즘에 관한 분야입니다.\n",
    "그 하위 개념인 딥러닝은, 계층 구조를 통해 자체적으로 배우고 결정을 내리는 인공신경망을 기반으로 한다는 특징이 있습니다.\n",
    "\n",
    "차이점이 있자면, \n",
    "머신러닝은 데이터를 나타내는 자료구조에 따라 다양한 형태를 지닌 반면, 딥러닝은 모두 인공신경망으로 이루어져 있다는 점입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이하 라이브러리를 불러오는 구문\n",
    "- torch : facebook에서 제공하는 딥러닝 도구\n",
    "- torchvision : 파이토치에서 제공하는 라이브러리. dataset 및 모듈 등을 포함.\n",
    "  * torchvision.transforms => Compose() 함수 등으로 전처리 진행.\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 하나의 GPU 활용이 가능한지 torch.cuda.is_available() 함수로 확인하고, 난수 시드값을 고정하는 과정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(45)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device + \" is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "학습에 필요한 parameter 값을 미리 정의함.\n",
    "- learning_rate = 학습하는 과정 속에서 기울기의 이동 step 정도값이다.\n",
    "- batch_size = 한번의 epoch를 돌때 데이터를 쪼개는데, 쪼개진 데이터의 크기를 의미한다.\n",
    "- num_classes = 분류에 활용될 클래스의 개수를 의미한다.\n",
    "- epochs = 전체 데이터 셋에 대해 학습을 완료하는 횟수 (forward/backward)\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습에 활용할 데이터 셋을 MNIST에서 불러와서 곧바로 Compose() 함수를 통해 전처리를 진행했다.\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor() \n",
    "    ])\n",
    ")\n",
    "\n",
    "# 검증용 데이터 셋을 MNIST에서 불러와서 곧바로 Compose() 함수를 통해 전처리를 진행했다.\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataLoader를 통해 우리가 불러올 데이터 set을 불러오고, batch_size 등 옵션값을 정해준다.\n",
    "# parameter 중 suffle 까지 설정하면 데이터를 무작위로 섞어서 사용할 수도 있다.\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# enumerate()를 통해 TrainSet의 원소마다 tuple 생성\n",
    "# example을 보기 위해 첫 원소를 뽑아서 할당해준다.\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 신경망을 구현한 부분이다.\n",
    "class ConvNet(nn.Module):\n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__() \n",
    "        # 첫 번째 합성곱 층은 1채널을 입력받아서 10개의 채널을 출력함. 5x5 정사각 컨볼루션 행렬\n",
    "        # 두 번째 합성곱 층은 10채널을 입력받아서 20개의 채널을 출력함. 5x5 정사각 컨볼루션 행렬\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        \n",
    "        # 과적합을 막기 위해서 Dropout을 적용했다. p값은 해당 원소가 영점조절(zeroed)될 확률.\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) \n",
    "        \n",
    "        # 커널 사이즈가 2로 설정된 MaxPooling\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Fully Connected (일반 신경망) 계층을 거치면서, 출력 크기 감소 > 분류해야할 클래스 개수인 10까지 감소.\n",
    "        # 초기 Input이 320인 이유 > 4 * 4 * 20 (2x2 Filter가 5x5 행렬에서 뽑아내는 feature)\n",
    "        # 중간에 100은 큰 의미없는 중간값이라고 한다 (100 말고 50 정도여도 괜찮음)\n",
    "        self.fc1 = nn.Linear(320,100) \n",
    "        self.fc2 = nn.Linear(100,10) \n",
    "        \n",
    "        # CNN 레이어 2개, FC 레이어 2개로 구성되어있으며, 중간중간 pooling을 진행 함.\n",
    "\n",
    "  def forward(self, x):\n",
    "        # conv > pooling > relu(활성화) 함수로 구성됨\n",
    "        # pooling은 2x2 커널로 진행\n",
    "        x = F.relu(self.mp(self.conv1(x))) \n",
    "        x = F.relu(self.mp(self.conv2(x))) \n",
    "        x = self.drop2D(x) \n",
    "        \n",
    "        # 2차원에서 1차원 형태로 변경한다 (FC 레이어에 넣기 위해)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # 10개의 클래스에 대해서 확률값으로 정규화해주는 softmax 함수 사용\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model > 방금 정의한 합성곱 신경망 클래스의 객체\n",
    "# criterion > loss 함수로 CrossEntropyLoss() 함수를 사용했음.\n",
    "# optimizer > 학습 셋을 이용해서 모델을 학습할때 실제 결과와 모델의 예측결과를 기반으로 차이를 잘 줄여줄 수 있도록 해줌.\n",
    "# 찾아보니 Adam이 가장 많이 사용하는 Optimizer이라고 한다.\n",
    "model = ConvNet().to(device) \n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dksu4\\AppData\\Local\\Temp\\ipykernel_50964\\2163771082.py:37: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1]  cost = 0.331803977\n",
      "[Epoch:    2]  cost = 0.111059882\n",
      "[Epoch:    3]  cost = 0.0861956701\n",
      "[Epoch:    4]  cost = 0.0733706281\n",
      "[Epoch:    5]  cost = 0.0666975453\n"
     ]
    }
   ],
   "source": [
    "# Epoch마다 훈련을 진행한다.\n",
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # backward를 호출하기 전에, 버퍼에 누적된 변화도를 초기화.\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        hypothesis = model(data)\n",
    "        # 아까 정의한 loss함수를 통해 Cost를 계산한다.\n",
    "        cost = criterion(hypothesis, target) \n",
    "        \n",
    "        # 모델의 매개변수들에 대한 손실의 변화도를 계산한다!\n",
    "        cost.backward()\n",
    "        \n",
    "        # 계산한 변화도에 따라 매개변수 갱신.\n",
    "        optimizer.step() \n",
    "        \n",
    "        avg_cost += cost / len(train_loader) \n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dksu4\\AppData\\Local\\Temp\\ipykernel_50964\\2163771082.py:37: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  98.59 %\n"
     ]
    }
   ],
   "source": [
    "# model.eval() 함수를 통해 tain time과 eval time에서 수행하는 다른 작업을 수행하기 위해 switching.\n",
    "# evaluation 과정에서 사용되면 안되는 layer를 off하는 함수라고 함.\n",
    "# train 과정으로 돌아가야 한다면, model.train() 실행 필요.\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # test 데이터를 학습시킨 모델에 넣어서 tensor를 반환받는다.\n",
    "        out = model(data)\n",
    "        \n",
    "        # max함수를 통해, tensor에서 최대값(젤 높은 확률값)을 뽑아냄.\n",
    "        preds = torch.max(out.data, 1)[1] \n",
    "        \n",
    "        # 텐서끼리 비교한 후, 답과 일치하는 값의 개수를 뽑아낸다.\n",
    "        total += len(target) \n",
    "        correct += (preds==target).sum().item() \n",
    "        \n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "투빅스 화이팅."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
